{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgUZio3slQua"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install gradio==6.3.0 git+https://github.com/huggingface/transformers.git\n",
        "!pip install opencv-python torch torchvision pillow accelerate easydict spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0t7zVluCmR_U"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
        "import spaces\n",
        "\n",
        "MODEL_PATH = \"strangervisionhf/PaddleOCR-VL-1.5-hf-transformers-v5.2.0.dev0\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"Loading model: {MODEL_PATH} on {DEVICE}...\")\n",
        "\n",
        "try:\n",
        "    model = AutoModelForImageTextToText.from_pretrained(\n",
        "        MODEL_PATH,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        trust_remote_code=True\n",
        "    ).to(DEVICE).eval()\n",
        "\n",
        "    processor = AutoProcessor.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
        "    print(\"Model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    raise e\n",
        "\n",
        "@spaces.GPU\n",
        "def process_ocr(image):\n",
        "    if image is None:\n",
        "        return \"Please upload an image.\"\n",
        "\n",
        "    image = image.convert(\"RGB\")\n",
        "\n",
        "    prompt_text = \"OCR:\"\n",
        "\n",
        "    max_pixels = 1280 * 28 * 28\n",
        "    min_pixels = 256 * 28 * 28\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"image\", \"image\": image},\n",
        "                {\"type\": \"text\", \"text\": prompt_text},\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    inputs = processor.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=True,\n",
        "        return_dict=True,\n",
        "        return_tensors=\"pt\",\n",
        "        images_kwargs={\n",
        "            \"size\": {\n",
        "                \"shortest_edge\": min_pixels,\n",
        "                \"longest_edge\": max_pixels\n",
        "            }\n",
        "        },\n",
        "    ).to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, max_new_tokens=512)\n",
        "\n",
        "    generated_text = processor.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# **PaddleOCR-VL-1.5 (Free-OCR)**\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            input_image = gr.Image(type=\"pil\", label=\"Input Image\")\n",
        "            run_btn = gr.Button(\"Extract Text\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Extracted Text\", lines=15)\n",
        "\n",
        "    run_btn.click(\n",
        "        fn=process_ocr,\n",
        "        inputs=[input_image],\n",
        "        outputs=output_text\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.queue().launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
