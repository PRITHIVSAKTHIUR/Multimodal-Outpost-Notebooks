{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHK9GOasNfam"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers-stream-generator huggingface_hub albumentations \\\n",
        "qwen-vl-utils pyvips-binary sentencepiece opencv-python docling-core \\\n",
        "transformers python-docx torchvision supervision matplotlib \\\n",
        "accelerate pdf2image num2words reportlab html2text markdown \\\n",
        "requests pymupdf loguru hf_xet spaces pyvips pillow gradio \\\n",
        "einops httpx numpy click torch peft fpdf timm av\n",
        "#Hold tight, this will take around 1-2 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbaT9hmaOoEc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import uuid\n",
        "import json\n",
        "import time\n",
        "from threading import Thread\n",
        "from typing import Iterable\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "import gradio as gr\n",
        "import spaces\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "from transformers import (\n",
        "    Qwen3VLForConditionalGeneration,\n",
        "    AutoProcessor,\n",
        "    TextIteratorStreamer,\n",
        ")\n",
        "\n",
        "from transformers.image_utils import load_image\n",
        "\n",
        "css = \"\"\"\n",
        "#main-title h1 {\n",
        "    font-size: 2.3em !important;\n",
        "}\n",
        "#output-title h2 {\n",
        "    font-size: 2.1em !important;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "MAX_MAX_NEW_TOKENS = 4096\n",
        "DEFAULT_MAX_NEW_TOKENS = 1024\n",
        "MAX_INPUT_TOKEN_LENGTH = int(os.getenv(\"MAX_INPUT_TOKEN_LENGTH\", \"4096\"))\n",
        "\n",
        "# Load Chandra-OCR\n",
        "MODEL_ID_V = \"datalab-to/chandra\"\n",
        "processor = AutoProcessor.from_pretrained(MODEL_ID_V, trust_remote_code=True)\n",
        "model = Qwen3VLForConditionalGeneration.from_pretrained(\n",
        "    MODEL_ID_V,\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16\n",
        ").to(device).eval()\n",
        "\n",
        "@spaces.GPU\n",
        "def generate_image(text: str, image: Image.Image,\n",
        "                   max_new_tokens: int, temperature: float, top_p: float,\n",
        "                   top_k: int, repetition_penalty: float):\n",
        "    \"\"\"\n",
        "    Generates responses using the Chandra-OCR model for image input.\n",
        "    Yields raw text and Markdown-formatted text.\n",
        "    \"\"\"\n",
        "    if image is None:\n",
        "        yield \"Please upload an image.\", \"Please upload an image.\"\n",
        "        return\n",
        "\n",
        "    messages = [{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\"},\n",
        "            {\"type\": \"text\", \"text\": text},\n",
        "        ]\n",
        "    }]\n",
        "    prompt_full = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "    inputs = processor(\n",
        "        text=[prompt_full],\n",
        "        images=[image],\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True).to(device)\n",
        "\n",
        "    streamer = TextIteratorStreamer(processor, skip_prompt=True, skip_special_tokens=True)\n",
        "    generation_kwargs = {\n",
        "        **inputs,\n",
        "        \"streamer\": streamer,\n",
        "        \"max_new_tokens\": max_new_tokens,\n",
        "        \"do_sample\": True,\n",
        "        \"temperature\": temperature,\n",
        "        \"top_p\": top_p,\n",
        "        \"top_k\": top_k,\n",
        "        \"repetition_penalty\": repetition_penalty,\n",
        "    }\n",
        "    thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
        "    thread.start()\n",
        "    buffer = \"\"\n",
        "    for new_text in streamer:\n",
        "        buffer += new_text\n",
        "        buffer = buffer.replace(\"<|im_end|>\", \"\")\n",
        "        time.sleep(0.01)\n",
        "        yield buffer, buffer\n",
        "\n",
        "with gr.Blocks(css=css) as demo:\n",
        "    gr.Markdown(\"# **Chandra-OCR**\", elem_id=\"main-title\")\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            image_query = gr.Textbox(label=\"Query Input\", placeholder=\"Enter your query here...\")\n",
        "            image_upload = gr.Image(type=\"pil\", label=\"Upload Image\", height=290)\n",
        "\n",
        "            image_submit = gr.Button(\"Submit\", variant=\"primary\")\n",
        "\n",
        "            with gr.Accordion(\"Advanced options\", open=False):\n",
        "                max_new_tokens = gr.Slider(label=\"Max new tokens\", minimum=1, maximum=MAX_MAX_NEW_TOKENS, step=1, value=DEFAULT_MAX_NEW_TOKENS)\n",
        "                temperature = gr.Slider(label=\"Temperature\", minimum=0.1, maximum=4.0, step=0.1, value=0.7)\n",
        "                top_p = gr.Slider(label=\"Top-p (nucleus sampling)\", minimum=0.05, maximum=1.0, step=0.05, value=0.9)\n",
        "                top_k = gr.Slider(label=\"Top-k\", minimum=1, maximum=1000, step=1, value=50)\n",
        "                repetition_penalty = gr.Slider(label=\"Repetition penalty\", minimum=1.0, maximum=2.0, step=0.05, value=1.1)\n",
        "\n",
        "        with gr.Column(scale=3):\n",
        "                gr.Markdown(\"## Output\", elem_id=\"output-title\")\n",
        "                output = gr.Textbox(label=\"Raw Output Stream\", interactive=False, lines=11, show_copy_button=True)\n",
        "                with gr.Accordion(\"(Result.md)\", open=False):\n",
        "                    markdown_output = gr.Markdown(label=\"(Result.Md)\")\n",
        "\n",
        "    image_submit.click(\n",
        "        fn=generate_image,\n",
        "        inputs=[image_query, image_upload, max_new_tokens, temperature, top_p, top_k, repetition_penalty],\n",
        "        outputs=[output, markdown_output]\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.queue(max_size=50).launch(mcp_server=True, ssr_mode=False, show_error=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}