{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHK9GOasNfam"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers-stream-generator huggingface_hub albumentations \\\n",
        "qwen-vl-utils pyvips-binary sentencepiece opencv-python docling-core \\\n",
        "transformers python-docx torchvision supervision matplotlib \\\n",
        "accelerate pdf2image num2words reportlab html2text markdown \\\n",
        "requests pymupdf loguru hf_xet spaces pyvips pillow gradio \\\n",
        "einops httpx numpy click torch peft fpdf timm av\n",
        "#Hold tight, this will take around 1-2 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbaT9hmaOoEc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import uuid\n",
        "import json\n",
        "import time\n",
        "import asyncio\n",
        "from threading import Thread\n",
        "from typing import Iterable\n",
        "\n",
        "import gradio as gr\n",
        "import spaces\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "from transformers import (\n",
        "    Qwen3VLForConditionalGeneration,\n",
        "    AutoTokenizer,\n",
        "    AutoProcessor,\n",
        "    TextIteratorStreamer,\n",
        ")\n",
        "from transformers.image_utils import load_image\n",
        "from gradio.themes import Soft\n",
        "from gradio.themes.utils import colors, fonts, sizes\n",
        "\n",
        "colors.steel_blue = colors.Color(\n",
        "    name=\"steel_blue\",\n",
        "    c50=\"#EBF3F8\",\n",
        "    c100=\"#D3E5F0\",\n",
        "    c200=\"#A8CCE1\",\n",
        "    c300=\"#7DB3D2\",\n",
        "    c400=\"#529AC3\",\n",
        "    c500=\"#4682B4\",\n",
        "    c600=\"#3E72A0\",\n",
        "    c700=\"#36638C\",\n",
        "    c800=\"#2E5378\",\n",
        "    c900=\"#264364\",\n",
        "    c950=\"#1E3450\",\n",
        ")\n",
        "\n",
        "class SteelBlueTheme(Soft):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        primary_hue: colors.Color | str = colors.gray,\n",
        "        secondary_hue: colors.Color | str = colors.steel_blue,\n",
        "        neutral_hue: colors.Color | str = colors.slate,\n",
        "        text_size: sizes.Size | str = sizes.text_lg,\n",
        "        font: fonts.Font | str | Iterable[fonts.Font | str] = (\n",
        "            fonts.GoogleFont(\"Outfit\"), \"Arial\", \"sans-serif\",\n",
        "        ),\n",
        "        font_mono: fonts.Font | str | Iterable[fonts.Font | str] = (\n",
        "            fonts.GoogleFont(\"IBM Plex Mono\"), \"ui-monospace\", \"monospace\",\n",
        "        ),\n",
        "    ):\n",
        "        super().__init__(\n",
        "            primary_hue=primary_hue,\n",
        "            secondary_hue=secondary_hue,\n",
        "            neutral_hue=neutral_hue,\n",
        "            text_size=text_size,\n",
        "            font=font,\n",
        "            font_mono=font_mono,\n",
        "        )\n",
        "        super().set(\n",
        "            background_fill_primary=\"*primary_50\",\n",
        "            background_fill_primary_dark=\"*primary_900\",\n",
        "            body_background_fill=\"linear-gradient(135deg, *primary_200, *primary_100)\",\n",
        "            body_background_fill_dark=\"linear-gradient(135deg, *primary_900, *primary_800)\",\n",
        "            button_primary_text_color=\"white\",\n",
        "            button_primary_text_color_hover=\"white\",\n",
        "            button_primary_background_fill=\"linear-gradient(90deg, *secondary_500, *secondary_600)\",\n",
        "            button_primary_background_fill_hover=\"linear-gradient(90deg, *secondary_600, *secondary_700)\",\n",
        "            button_primary_background_fill_dark=\"linear-gradient(90deg, *secondary_600, *secondary_800)\",\n",
        "            button_primary_background_fill_hover_dark=\"linear-gradient(90deg, *secondary_500, *secondary_500)\",\n",
        "            button_secondary_text_color=\"black\",\n",
        "            button_secondary_text_color_hover=\"white\",\n",
        "            button_secondary_background_fill=\"linear-gradient(90deg, *primary_300, *primary_300)\",\n",
        "            button_secondary_background_fill_hover=\"linear-gradient(90deg, *primary_400, *primary_400)\",\n",
        "            button_secondary_background_fill_dark=\"linear-gradient(90deg, *primary_500, *primary_600)\",\n",
        "            button_secondary_background_fill_hover_dark=\"linear-gradient(90deg, *primary_500, *primary_500)\",\n",
        "            slider_color=\"*secondary_500\",\n",
        "            slider_color_dark=\"*secondary_600\",\n",
        "            block_title_text_weight=\"600\",\n",
        "            block_border_width=\"3px\",\n",
        "            block_shadow=\"*shadow_drop_lg\",\n",
        "            button_primary_shadow=\"*shadow_drop_lg\",\n",
        "            button_large_padding=\"11px\",\n",
        "            color_accent_soft=\"*primary_100\",\n",
        "            block_label_background_fill=\"*primary_200\",\n",
        "        )\n",
        "\n",
        "steel_blue_theme = SteelBlueTheme()\n",
        "\n",
        "MAX_MAX_NEW_TOKENS = 4096\n",
        "DEFAULT_MAX_NEW_TOKENS = 1024\n",
        "MAX_INPUT_TOKEN_LENGTH = int(os.getenv(\"MAX_INPUT_TOKEN_LENGTH\", \"4096\"))\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "MODEL_ID = \"Qwen/Qwen3-VL-2B-Instruct\"\n",
        "processor = AutoProcessor.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
        "model = Qwen3VLForConditionalGeneration.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16\n",
        ").to(device).eval()\n",
        "\n",
        "def downsample_video(video_path):\n",
        "    \"\"\"\n",
        "    Downsamples the video to evenly spaced frames.\n",
        "    Each frame is returned as a PIL image along with its timestamp.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        vidcap = cv2.VideoCapture(video_path)\n",
        "        total_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        if total_frames <= 0:\n",
        "            return []\n",
        "        fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
        "        frames = []\n",
        "        # Use a maximum of 10 frames to avoid excessive memory usage\n",
        "        frame_indices = np.linspace(0, total_frames - 1, min(total_frames, 10), dtype=int)\n",
        "        for i in frame_indices:\n",
        "            vidcap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "            success, image = vidcap.read()\n",
        "            if success:\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "                pil_image = Image.fromarray(image)\n",
        "                timestamp = round(i / fps, 2) if fps > 0 else 0.0\n",
        "                frames.append((pil_image, timestamp))\n",
        "    finally:\n",
        "        if vidcap:\n",
        "            vidcap.release()\n",
        "    return frames\n",
        "\n",
        "@spaces.GPU\n",
        "def generate_image(text: str, image: Image.Image,\n",
        "                   max_new_tokens: int = 1024,\n",
        "                   temperature: float = 0.6,\n",
        "                   top_p: float = 0.9,\n",
        "                   top_k: int = 50,\n",
        "                   repetition_penalty: float = 1.2):\n",
        "    \"\"\"\n",
        "    Generates responses using the Qwen3-VL model for image input.\n",
        "    \"\"\"\n",
        "    if image is None:\n",
        "        yield \"Please upload an image.\", \"Please upload an image.\"\n",
        "        return\n",
        "\n",
        "    messages = [{\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": text}]}]\n",
        "    prompt_full = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = processor(\n",
        "        text=[prompt_full], images=[image], return_tensors=\"pt\", padding=True).to(device)\n",
        "    streamer = TextIteratorStreamer(processor, skip_prompt=True, skip_special_tokens=True)\n",
        "\n",
        "    generation_kwargs = {\n",
        "        **inputs,\n",
        "        \"streamer\": streamer,\n",
        "        \"max_new_tokens\": max_new_tokens,\n",
        "        \"do_sample\": True,\n",
        "        \"temperature\": temperature,\n",
        "        \"top_p\": top_p,\n",
        "        \"top_k\": top_k,\n",
        "        \"repetition_penalty\": repetition_penalty,\n",
        "    }\n",
        "\n",
        "    thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
        "    thread.start()\n",
        "\n",
        "    buffer = \"\"\n",
        "    for new_text in streamer:\n",
        "        buffer += new_text\n",
        "        time.sleep(0.01)\n",
        "        yield buffer, buffer\n",
        "\n",
        "@spaces.GPU\n",
        "def generate_video(text: str, video_path: str,\n",
        "                   max_new_tokens: int = 1024,\n",
        "                   temperature: float = 0.6,\n",
        "                   top_p: float = 0.9,\n",
        "                   top_k: int = 50,\n",
        "                   repetition_penalty: float = 1.2):\n",
        "    \"\"\"\n",
        "    Generates responses using the Qwen3-VL model for video input.\n",
        "    \"\"\"\n",
        "    if video_path is None:\n",
        "        yield \"Please upload a video.\", \"Please upload a video.\"\n",
        "        return\n",
        "\n",
        "    frames_with_ts = downsample_video(video_path)\n",
        "    if not frames_with_ts:\n",
        "        yield \"Could not process the video. Please try another file.\", \"Could not process the video. Please try another file.\"\n",
        "        return\n",
        "\n",
        "    # Prepare messages for the model\n",
        "    messages = [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"These are frames from a video. \" + text}]}]\n",
        "    images_for_processor = []\n",
        "    for frame, timestamp in frames_with_ts:\n",
        "        messages[0][\"content\"].insert(0, {\"type\": \"image\"}) # Prepend images\n",
        "        images_for_processor.append(frame)\n",
        "\n",
        "    prompt_full = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = processor(\n",
        "        text=[prompt_full], images=images_for_processor, return_tensors=\"pt\", padding=True).to(device)\n",
        "    streamer = TextIteratorStreamer(processor, skip_prompt=True, skip_special_tokens=True)\n",
        "\n",
        "    generation_kwargs = {\n",
        "        **inputs,\n",
        "        \"streamer\": streamer,\n",
        "        \"max_new_tokens\": max_new_tokens,\n",
        "        \"do_sample\": True,\n",
        "        \"temperature\": temperature,\n",
        "        \"top_p\": top_p,\n",
        "        \"top_k\": top_k,\n",
        "        \"repetition_penalty\": repetition_penalty,\n",
        "    }\n",
        "\n",
        "    thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
        "    thread.start()\n",
        "\n",
        "    buffer = \"\"\n",
        "    for new_text in streamer:\n",
        "        buffer += new_text\n",
        "        time.sleep(0.01)\n",
        "        yield buffer, buffer\n",
        "\n",
        "css = \"\"\"\n",
        "#main-title {\n",
        "    text-align: center;\n",
        "}\n",
        "#main-title h1 {\n",
        "    font-size: 2.5em !important;\n",
        "    font-weight: 700;\n",
        "}\n",
        "#output-title h2 {\n",
        "    font-size: 2.1em !important;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Create the Gradio Interface\n",
        "with gr.Blocks(css=css, theme=steel_blue_theme) as demo:\n",
        "    gr.Markdown(\"# **Qwen3-VL Outpost**\", elem_id=\"main-title\")\n",
        "    gr.Markdown(\"### A Gradio interface for the powerful Qwen3-VL-2B-Instruct model.\", elem_id=\"main-title\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            with gr.Tabs():\n",
        "                with gr.TabItem(\"üñºÔ∏è Image Inference\"):\n",
        "                    image_query = gr.Textbox(label=\"Query Input\", placeholder=\"Enter your query here...\")\n",
        "                    image_upload = gr.Image(type=\"pil\", label=\"Upload Image\", height=320)\n",
        "                    image_submit = gr.Button(\"Submit\", variant=\"primary\")\n",
        "\n",
        "                with gr.TabItem(\"üé¨ Video Inference\"):\n",
        "                    video_query = gr.Textbox(label=\"Query Input\", placeholder=\"Enter your query here...\")\n",
        "                    video_upload = gr.Video(label=\"Upload Video\", height=320)\n",
        "                    video_submit = gr.Button(\"Submit\", variant=\"primary\")\n",
        "\n",
        "            with gr.Accordion(\"Advanced Generation Options\", open=False):\n",
        "                max_new_tokens = gr.Slider(label=\"Max New Tokens\", minimum=1, maximum=MAX_MAX_NEW_TOKENS, step=1, value=DEFAULT_MAX_NEW_TOKENS)\n",
        "                temperature = gr.Slider(label=\"Temperature\", minimum=0.1, maximum=2.0, step=0.1, value=0.7)\n",
        "                top_p = gr.Slider(label=\"Top-P (Nucleus Sampling)\", minimum=0.05, maximum=1.0, step=0.05, value=0.9)\n",
        "                top_k = gr.Slider(label=\"Top-K\", minimum=1, maximum=1000, step=1, value=50)\n",
        "                repetition_penalty = gr.Slider(label=\"Repetition Penalty\", minimum=1.0, maximum=2.0, step=0.05, value=1.2)\n",
        "\n",
        "        with gr.Column(scale=3):\n",
        "            gr.Markdown(\"## üí° Model Output\", elem_id=\"output-title\")\n",
        "            output = gr.Textbox(label=\"Raw Output Stream\", interactive=False, lines=13, show_copy_button=True)\n",
        "            with gr.Accordion(\"Formatted Markdown Output\", open=True):\n",
        "                markdown_output = gr.Markdown()\n",
        "\n",
        "    advanced_inputs = [max_new_tokens, temperature, top_p, top_k, repetition_penalty]\n",
        "\n",
        "    image_submit.click(\n",
        "        fn=generate_image,\n",
        "        inputs=[image_query, image_upload] + advanced_inputs,\n",
        "        outputs=[output, markdown_output]\n",
        "    )\n",
        "\n",
        "    video_submit.click(\n",
        "        fn=generate_video,\n",
        "        inputs=[video_query, video_upload] + advanced_inputs,\n",
        "        outputs=[output, markdown_output]\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.queue(max_size=50).launch(ssr_mode=False, show_error=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}