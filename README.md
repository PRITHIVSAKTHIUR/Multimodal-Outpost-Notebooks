# **Multimodal-Outpost-Notebooks**

> **Multimodal-Outpost** is a collection of Colab notebooks designed for image inference and multimodal vision-language model (VLM) experimentation. It provides tools for OCR, image captioning, and generating DOCX or PDF documents containing both images and extracted text.

## Notebooks

This repository includes notebooks for:

* **Nanonets OCR**
* **Monkey OCR**
* **OCRFlux 3B**
* **Typhoon OCR**

## Features

* Extracts text from images using various OCR models
* Supports image captioning and multimodal inference
* Embeds images and extracted text into DOCX or PDF formats
* Designed for quick deployment via Google Colab

## Supported Models

* **Nanonets OCR**
* **Monkey OCR**
* **OCRFlux 3B**
* **Typhoon OCR 3B**

---

## Other Images

<table border="1" style="width:100%; table-layout:fixed;">
  <tr>
    <td style="text-align:center;">
      <img src="https://github.com/user-attachments/assets/88429981-84d0-40b2-8d99-546c439d36f3" alt="OCR" width="100%">
      <p>OCR</p>
    </td>
    <td style="text-align:center;">
      <img src="https://github.com/user-attachments/assets/bb6bfbb5-3313-47c5-988e-47083531e398" alt="Caption" width="100%">
      <p>Caption</p>
    </td>
  </tr>
</table>

---

![222](https://github.com/user-attachments/assets/eae0f85d-2963-4edf-96e9-caedfe048c4f)

---

## Dependencies

* Python
* PyTorch
* Hugging Face Transformers
* ReportLab
* Gradio (for UI)
* (Qwen2.5-VL based)

All dependencies are automatically installed in the Colab environment.

## Author

Created and maintained by [PRITHIVSAKTHIUR](https://github.com/PRITHIVSAKTHIUR)
